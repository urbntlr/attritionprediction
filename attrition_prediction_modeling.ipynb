{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attrition prediction modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import graphviz \n",
    "\n",
    "# preprocessing & \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as make_imb_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import  PolynomialFeatures, StandardScaler, RobustScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ML models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "# Deep learning\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# feature importance shap values\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import shap\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, plot_confusion_matrix\n",
    "\n",
    "# system\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### data cohort 1\n",
    "df = pd.read_csv('cohort1.csv')\n",
    "\n",
    "# rows with NaN values\n",
    "df[df.isna().any(axis=1)]\n",
    "\n",
    "# remove all rows with NaN values\n",
    "df = df.dropna()\n",
    "#df.head()\n",
    "\n",
    "### data cohort 1\n",
    "df2 = pd.read_csv('cohort2.csv')\n",
    "\n",
    "# rows with NaN values\n",
    "df2[df2.isna().any(axis=1)]\n",
    "\n",
    "# remove all rows with NaN values\n",
    "df2 = df2.dropna()\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Winsorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# store original df for comparison\n",
    "df_org = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Apply winsorization to train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# exlcude variables frequency below winsorization level \n",
    "winsorization_col = list(df.columns)\n",
    "exception_list = ['incoming_transfer_on_investment','outgoing_transfer_on_investment',\n",
    "                  'profit_on_volume_futures','volume_etf_funds_perc','rec_outgoing_transfer',\n",
    "                 'volume_futures_perc','is_negative_feedback']\n",
    "winsorization_col = [x for x in winsorization_col if x not in exception_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# winsorize each column and store min and max values in a new dataframe\n",
    "winsorize_level = pd.DataFrame(index = ['Min', 'Max'])\n",
    "lower = 0.01\n",
    "upper = 0.01\n",
    "\n",
    "for column in winsorization_col:\n",
    "    df[column] = winsorize(df[column],(lower,upper))\n",
    "    winsorize_level[column] = [min(df[column]),max(df[column])]\n",
    "winsorize_level    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot boxplot for one variable as an example\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Example of variable before and after winsorization (volume_open_closing_ratio)')\n",
    "ax1.boxplot(df2['volume_open_closing_ratio'])\n",
    "ax2.boxplot(df['volume_open_closing_ratio'])\n",
    "\n",
    "ax1.set_xticklabels(['Before'], fontdict=None, minor=False)\n",
    "ax2.set_xticklabels(['After'], fontdict=None, minor=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Apply winsorization to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for column in winsorization_col:\n",
    "    winsorize_min = winsorize_level[column].loc['Min']\n",
    "    winsorize_max = winsorize_level[column].loc['Max']\n",
    "    df2.loc[df2[column] > winsorize_max, column] = winsorize_max\n",
    "    df2.loc[df2[column] < winsorize_min, column] = winsorize_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# describe data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculate attrition\n",
    "n_cohort1 = df.shape[0]\n",
    "n_cohort2 = df2.shape[0]\n",
    "\n",
    "attrition_cohort1 = len(df[(df['is_attrition']==1)])\n",
    "attrition_cohort2 = len(df2[(df2['is_attrition']==1)])\n",
    "\n",
    "attrition_rate_cohort1 = attrition_cohort1 / n_cohort1\n",
    "attrition_rate_cohort2 = attrition_cohort2 / n_cohort2\n",
    "\n",
    "print('Cohort January 2018 (No. of attrition =',attrition_cohort1,'; n =', n_cohort1,'; attrition rate =',round(attrition_rate_cohort1 * 100,2) ,'%)')\n",
    "print('Cohort February 2018 (No. of attrition =',attrition_cohort2,'; n =', n_cohort2,'; attrition rate =',round(attrition_rate_cohort2 * 100,2) ,'%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot attrition for train and test dataset\n",
    "list1 = [[0,n_cohort1 - attrition_cohort1], [1,attrition_cohort1]]\n",
    "list2 = [[0,n_cohort2 - attrition_cohort2], [1,attrition_cohort2]]\n",
    "\n",
    "dfs = [pd.DataFrame(np.array(lst), \n",
    "                    columns=['is_attrition', i]).set_index('is_attrition')\n",
    "          for i,lst in enumerate([list1,list2])]\n",
    "\n",
    "dfs_plot = pd.concat(dfs, axis=1)\n",
    "\n",
    "dfs_plot.plot.bar(color = ['blue','cornflowerblue']).legend(['Train (in-sample)', 'Test (OOP)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot all features to visualize patterns in data\n",
    "df2.plot(lw=0,\n",
    "          marker=\".\",\n",
    "          subplots=True,\n",
    "          layout=(-1, 4),\n",
    "          figsize=(15, 30),\n",
    "          markersize=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Histogram for each feature with attrition overlay\n",
    "\n",
    "# Per class feature histogram\n",
    "fig, axes = plt.subplots (20, 3, figsize=(20, 70))\n",
    "fig.suptitle(\"Feature Distribution\" , fontsize=20, y=0.95)\n",
    "attrition = df.loc[df['is_attrition'] == 1]\n",
    "no_attrition = df.loc[df['is_attrition'] == 0]\n",
    "\n",
    "#no_purchase\n",
    "ax = axes.ravel()\n",
    "print(ax)\n",
    "\n",
    "bins = 50\n",
    "\n",
    "for i in range(54):\n",
    "    ax[i].hist(no_attrition.iloc[:,i], bins = bins, color = \"orange\", alpha = 0.5)\n",
    "    ax[i].hist(attrition.iloc[:,i], bins = bins, color = \"blue\", alpha = 0.5)\n",
    "    ax[i].set_title(df.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot correlation plot for all feature combinations\n",
    "# Creates mask to identify numerical features with at least 25 unique features\n",
    "\n",
    "#cols_continuous = df.select_dtypes(include=\"number\").nunique() >= 10\n",
    "\n",
    "# Create a new dataframe which only contains the continuous features\n",
    "\n",
    "#df_continuous = df[cols_continuous[cols_continuous].index]\n",
    "\n",
    "#sns.pairplot(df_continuous, height=1.5,\n",
    "#             plot_kws={\"s\": 2, \"alpha\": 0.2});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Remove highly correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computes feature correlation\n",
    "df_corr = df.loc[:, ~df.columns.isin(['is_attrition', 'is_female','is_positive_feedback'\n",
    "                                      ,'is_negative_feedback','is_withdrawal_last_month'\n",
    "                                      ,'is_withdrawal_last_week','is_deposit_last_month'\n",
    "                                      ,'is_deposit_last_week']\n",
    "                                    )].corr(method=\"pearson\",min_periods=1)\n",
    "\n",
    "mask = np.zeros_like(df_corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Create labels for the correlation matrix\n",
    "labels = np.where(np.abs(df_corr)>0.90, \"S\",\n",
    "                  np.where(np.abs(df_corr)>0.5, \"M\",\n",
    "                           np.where(np.abs(df_corr)>0.05, \"W\", \"\")))\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(df_corr, mask=mask, square=True,\n",
    "            center=0, annot=labels, fmt='', linewidths=.5,\n",
    "            cmap=\"vlag\", cbar_kws={\"shrink\": 0.8});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print correlation matrix\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Above chart shows that num_orders highly correlates with num_BO_SO_orders and num_BC_SC_orders\n",
    "\n",
    "# drop from train set\n",
    "df.drop(['num_orders','num_orders_last_month','num_orders_last_week','rec_num_orders'], axis=1, inplace=True)\n",
    "\n",
    "# drop from test set\n",
    "df2.drop(['num_orders','num_orders_last_month','num_orders_last_week','rec_num_orders'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Plot variables highly correlated with attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "df_corr = df.loc[:, ~df.columns.isin(['is_female','is_positive_feedback','is_negative_feedback'])].corr(method=\"pearson\",min_periods=1)\n",
    "\n",
    "attrition_corr = df_corr['is_attrition'].sort_values(ascending=False)[1:].head(55)\n",
    "\n",
    "attrition_corr.plot.bar()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot histogram and 100% stacked histogram for selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "b='blue'  # first default color\n",
    "o='orange'  # second default color\n",
    "\n",
    "def plot_hist_norm(x0,x1,bins,title = 'test'):\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "    (n, bin_limits, _) = ax0.hist([x0,x1], bins=10,stacked=False,color=[o,b])\n",
    "    with np.errstate(divide='ignore',invalid='ignore'):\n",
    "        n_norm = n / n.sum(axis=0)\n",
    "    labels=np.round((bin_limits[1:]+bin_limits[:-1])/2,1)    # determine middle of classes\n",
    "    df_chart=pd.DataFrame({'0':n_norm[0,:],'1':n_norm[1,:]},index=labels)\n",
    "    df_chart.plot.bar(ax=ax1, stacked=True, figsize=(14, 2),color=[o,b])\n",
    "    ax0.set_title(title + ' histogram')\n",
    "    ax1.set_title(title + ' histogram normalized')\n",
    "    ax1.legend(['1', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_name = attrition_corr.index[:6]\n",
    "for col in column_name:\n",
    "    attr_data=df.loc[df.is_attrition==1,col]\n",
    "    no_attr_data=df.loc[df.is_attrition==0,col]\n",
    "    plot_hist_norm(attr_data,no_attr_data,10,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "df.loc[df['withdrawal_eur_last_month'] > 0, 'is_withdrawal_last_month'] = 1\n",
    "df.loc[df['withdrawal_eur_last_month'] == 0, 'is_withdrawal_last_month'] = 0\n",
    "\n",
    "df.loc[df['withdrawal_eur_last_week'] > 0, 'is_withdrawal_last_week'] = 1\n",
    "df.loc[df['withdrawal_eur_last_week'] == 0, 'is_withdrawal_last_week'] = 0\n",
    "\n",
    "df.loc[df['deposit_eur_last_month'] > 0, 'is_deposit_last_month'] = 1\n",
    "df.loc[df['deposit_eur_last_month'] == 0, 'is_deposit_last_month'] = 0\n",
    "\n",
    "df.loc[df['deposit_eur_last_week'] > 0, 'is_deposit_last_week'] = 1\n",
    "df.loc[df['deposit_eur_last_week'] == 0, 'is_deposit_last_week'] = 0\n",
    "\n",
    "# test\n",
    "df2.loc[df['withdrawal_eur_last_month'] > 0, 'is_withdrawal_last_month'] = 1\n",
    "df2.loc[df['withdrawal_eur_last_month'] == 0, 'is_withdrawal_last_month'] = 0\n",
    "\n",
    "df2.loc[df['withdrawal_eur_last_week'] > 0, 'is_withdrawal_last_week'] = 1\n",
    "df2.loc[df['withdrawal_eur_last_week'] == 0, 'is_withdrawal_last_week'] = 0\n",
    "\n",
    "df2.loc[df['deposit_eur_last_month'] > 0, 'is_deposit_last_month'] = 1\n",
    "df2.loc[df['deposit_eur_last_month'] == 0, 'is_deposit_last_month'] = 0\n",
    "\n",
    "df2.loc[df['deposit_eur_last_week'] > 0, 'is_deposit_last_week'] = 1\n",
    "df2.loc[df['deposit_eur_last_week'] == 0, 'is_deposit_last_week'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe().T.to_csv(\"descriptive_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Plot for upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create plot for upsampling\n",
    "list1 = [[0,n_cohort1 - attrition_cohort1], [1,attrition_cohort1]]\n",
    "list2 = [[0,n_cohort1 - attrition_cohort1], [1,n_cohort1 - attrition_cohort1]]\n",
    "\n",
    "dfs = [pd.DataFrame(np.array(lst), \n",
    "                    columns=['is_attrition', i]).set_index('is_attrition')\n",
    "          for i,lst in enumerate([list1,list2])]\n",
    "\n",
    "dfs_plot = pd.concat(dfs, axis=1)\n",
    "\n",
    "dfs_plot.plot.bar(color = ['orangered','mediumorchid']).legend(['Original', 'Upsampled'], loc = 'upper center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train-test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define train and test dataset\n",
    "\n",
    "X_train = df.loc[:, ~df.columns.isin(['is_attrition'])]\n",
    "y_train = df['is_attrition']\n",
    "X_test = df2.loc[:, ~df2.columns.isin(['is_attrition'])]\n",
    "y_test = df2['is_attrition']\n",
    "\n",
    "# split train dataset to train and valiadtion dataset. \n",
    "X_trainD, X_valid, y_trainD, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=3, stratify=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot first 2 PCAs\n",
    "df_plot_pca = pd.DataFrame({'1_pca':X_train_pca[:,0], '2_pca':X_train_pca[:,1], '3_pca':X_train_pca[:,2], 'y':y_train})\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "no_purchase = plt.scatter(df_plot_pca.loc[df_plot_pca['y'] == 0, ['1_pca']], df_plot_pca.loc[df_plot_pca['y'] == 0, ['2_pca']], marker='o', color=\"orange\", alpha=0.5, label='no_purchase')\n",
    "purchase = plt.scatter(df_plot_pca.loc[df_plot_pca['y'] == 1, ['1_pca']], df_plot_pca.loc[df_plot_pca['y'] == 1, ['2_pca']], marker='^', color=\"blue\", alpha=0.2, label='purchase')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(df_plot_pca.loc[df_plot_pca['y'] == 1, ['1_pca']], df_plot_pca.loc[df_plot_pca['y'] == 1, ['2_pca']], df_plot_pca.loc[df_plot_pca['y'] == 1, ['3_pca']], marker='^', color=\"blue\", alpha=0.2, label='purchase')\n",
    "ax.scatter(df_plot_pca.loc[df_plot_pca['y'] == 0, ['1_pca']], df_plot_pca.loc[df_plot_pca['y'] == 0, ['2_pca']], df_plot_pca.loc[df_plot_pca['y'] == 0, ['3_pca']], marker='o', color=\"orange\", alpha=0.5, label='no_purchase')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "ax.set_xlabel(\"First principal component\")\n",
    "ax.set_ylabel(\"Second principal component\")\n",
    "ax.set_zlabel('Third principal component')\n",
    "\n",
    "# rotate\n",
    "ax.view_init(-140, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(pca.components_,cmap='viridis')\n",
    "#plt.yticks([0,1,2],['First component','Second component','Third component'])\n",
    "plt.yticks(range(10),range(1,11))\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(X.columns)),X.columns, rotation=60, ha='left')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Principal components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "\n",
    "plt.figure(figsize=(18 , 10))\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_,'o')\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xticks(range(0,10,1),range(1,11))\n",
    "plt.xlabel('Principle Components')\n",
    "plt.ylabel('Eigen Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# function for displaying confusion matrix, ROC and classification report\n",
    "\n",
    "def plot_confusion_matrix(best_estimator ,name = 'Name not defined'):\n",
    "    \n",
    "    classifier = best_estimator\n",
    "\n",
    "    # Confusion matrix\n",
    "    title_options = [\n",
    "        (\"Confusion matrix, without normalization\", None),\n",
    "        (\"Normalized confusion matrix\", \"true\"),\n",
    "    ]\n",
    "    for title, normalize in title_options:\n",
    "        display = ConfusionMatrixDisplay.from_estimator(\n",
    "            classifier,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            cmap=plt.cm.Blues,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "        display.ax_.set_title(title)\n",
    "\n",
    "        #print(title)\n",
    "        #print(display.confusion_matrix)\n",
    "      \n",
    "    # ROC curve\n",
    "    RocCurveDisplay.from_estimator(best_estimator, X_test, y_test, name = name)\n",
    "    \n",
    "    # Classification report\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "    print('')\n",
    "    print('Classification Report')    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# function for displaying confusion matrix, ROC and classification report\n",
    "\n",
    "def plot_roc_curve(best_estimator ,name = 'Name not defined'):\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [6, 4]\n",
    "    classifier = best_estimator\n",
    "      \n",
    "    # ROC curve\n",
    "    RocCurveDisplay.from_estimator(best_estimator, X_test, y_test, name = name)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), RandomForestClassifier(warm_start=True, random_state=2))\n",
    "\n",
    "# cross validations\n",
    "cv = 3\n",
    "\n",
    "\n",
    "param_grid = {\"randomforestclassifier__n_estimators\": range(100)\n",
    "            ,'randomforestclassifier__max_depth' : [2,3,4,5,6,7,8,10]\n",
    "            ,'randomforestclassifier__criterion' :['entropy']\n",
    "            \n",
    "             }\n",
    "\n",
    "grid_rf = GridSearchCV(pipe, param_grid, return_train_score=True, cv=cv\n",
    "                       , scoring= 'f1_macro'\n",
    "                       ,n_jobs=-1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "#grid_rf.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_rf.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_rf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Plot the validation curve \n",
    "rf_p_results = pd.DataFrame(grid_rf.cv_results_)\n",
    "\n",
    "rf_p_results = rf_p_results[rf_p_results['param_randomforestclassifier__criterion']=='entropy']\n",
    "rf_p_results = rf_p_results[rf_p_results['param_randomforestclassifier__n_estimators']==39]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [7, 5]\n",
    "ax = plt.gca()\n",
    "ax.plot(rf_p_results[\"param_randomforestclassifier__max_depth\"], rf_p_results[\"mean_train_score\"], label='Training Score')\n",
    "ax.plot(rf_p_results[\"param_randomforestclassifier__max_depth\"], rf_p_results[\"mean_test_score\"], label='Cross-Validation Score')\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Validation Random Forest\")\n",
    "#plt.axis(\"tight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 15]\n",
    "\n",
    "plt.matshow(grid_rf.cv_results_['mean_test_score'].reshape(8,-1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.yticks(range(len(param_grid['randomforestclassifier__max_depth'])), param_grid['randomforestclassifier__max_depth'])\n",
    "plt.colorbar();\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_rf.best_estimator_, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 14]\n",
    "feature_importances = grid_rf.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_\n",
    "\n",
    "feat_importances = pd.Series(feature_importances, index=X_train.columns)\n",
    "#feat_importances = pd.Series(feature_importances, index=X.columns)\n",
    "feat_importances.nlargest(25).plot(kind='barh')\n",
    "plt.title(\"Features importances (Random Forest model)\")\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "\n",
    "feat_importances_rf = feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_estimator = grid_rf.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "#pd.set_option('precision', 2)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "# merge results\n",
    "\n",
    "#y_pred.shape\n",
    "overview = X_test.copy(deep=True)\n",
    "\n",
    "overview['pred_attrition'] = y_pred.tolist()\n",
    "\n",
    "overview = overview.groupby(['pred_attrition']).mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "overview['feat_importance'] = feat_importances.tolist()\n",
    "overview.nlargest(35, columns = 'feat_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), LogisticRegression(multi_class = 'auto', solver = 'lbfgs',random_state = 2, max_iter=10000))\n",
    "\n",
    "param_grid = {\"logisticregression__C\": np.logspace(-5,7)}\n",
    "grid_log = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, scoring= 'f1_macro', n_jobs=-1)\n",
    "grid_log.fit(X_train, y_train);\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_log.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_log.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Plot the validation curve\n",
    "log_results = pd.DataFrame(grid_log.cv_results_)\n",
    "\n",
    "#log_results = log_results[log_results['param_polynomialfeatures__degree']==1]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [7, 5]\n",
    "ax = plt.gca()\n",
    "ax.plot(log_results[\"param_logisticregression__C\"], log_results[\"mean_train_score\"], label='Training Score')\n",
    "ax.plot(log_results[\"param_logisticregression__C\"], log_results[\"mean_test_score\"], label='Cross-Validation Score')\n",
    "ax.set_xscale(\"log\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Validation Curve Logistic Regression\")\n",
    "plt.axis(\"tight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_log.best_estimator_, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 20]\n",
    "\n",
    "# get the best performing model fit on the whole training set\n",
    "best_model_log = grid_log.best_estimator_\n",
    "#best_model_log.steps[3]\n",
    "feat_importances = best_model_log.named_steps['logisticregression'].coef_[0]\n",
    "#importance = best_model_log.coef_[0]\n",
    "\n",
    "#importance[0]\n",
    "\n",
    "#feat_importances = pd.Series(importance)\n",
    "\n",
    "#feat_importances = pd.Series(importance[1:], index=X_train.columns)\n",
    "feat_importances = pd.Series(feat_importances, index=X_train.columns)\n",
    "\n",
    "feat_importances.nlargest(55).plot(kind='barh',title = 'Feature Importance')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "\n",
    "feat_importances_logr = feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_estimator = grid_log.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "#pd.set_option('precision', 2)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "# merge results\n",
    "\n",
    "#y_pred.shape\n",
    "overview = X_test.copy(deep=True)\n",
    "\n",
    "overview['pred_attrition'] = y_pred.tolist()\n",
    "\n",
    "overview = overview.groupby(['pred_attrition']).mean().T\n",
    "\n",
    "overview['feat_importance'] = feat_importances.tolist()\n",
    "overview.nlargest(55, columns = 'feat_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), LinearSVC(dual = False, random_state=2, max_iter=1000))\n",
    "\n",
    "param_grid = {\"linearsvc__C\": np.logspace(-2,10,8)}\n",
    "grid_svc = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, scoring= 'f1_macro',  n_jobs=-1)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_svc.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_svc.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Plot the validation curve\n",
    "svc_results = pd.DataFrame(grid_svc.cv_results_)\n",
    "\n",
    "#svc_results = svc_results[svc_results['param_polynomialfeatures__degree']==1]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [7, 5]\n",
    "ax = plt.gca()\n",
    "ax.plot(svc_results[\"param_linearsvc__C\"], svc_results[\"mean_train_score\"], label='Training Score')\n",
    "ax.plot(svc_results[\"param_linearsvc__C\"], svc_results[\"mean_test_score\"], label='Cross-Validation Score')\n",
    "ax.set_xscale(\"log\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Validation Curve Linear SVC\")\n",
    "plt.axis(\"tight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_svc.best_estimator_, 'Linear SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_estimator = grid_svc.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 20]\n",
    "\n",
    "#best_model_log.steps[3]\n",
    "feat_importances = best_estimator.named_steps['linearsvc'].coef_[0]\n",
    "\n",
    "feat_importances = pd.Series(feat_importances, index=X_train.columns)\n",
    "\n",
    "feat_importances.nlargest(55).plot(kind='barh',title = 'Feature Importance')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "\n",
    "feat_importances_svc = feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pd.set_option('precision', 2)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "# merge results\n",
    "\n",
    "#y_pred.shape\n",
    "overview = X_test.copy(deep=True)\n",
    "\n",
    "overview['pred_attrition'] = y_pred.tolist()\n",
    "\n",
    "overview = overview.groupby(['pred_attrition']).mean().T\n",
    "\n",
    "overview['feat_importance'] = feat_importances.tolist()\n",
    "overview.nlargest(55, columns = 'feat_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), KNeighborsClassifier())\n",
    "\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': range(1, 20)}\n",
    "grid_knn = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, scoring= 'f1_macro',  n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_knn.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_knn.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Plot the validation curve\n",
    "knn_results = pd.DataFrame(grid_knn.cv_results_)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(knn_results[\"param_kneighborsclassifier__n_neighbors\"], knn_results[\"mean_train_score\"], label='Training Score')\n",
    "ax.plot(knn_results[\"param_kneighborsclassifier__n_neighbors\"], knn_results[\"mean_test_score\"], label='Cross-Validation Score')\n",
    "#ax.set_xscale(\"log\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Validation Curve KNN\")\n",
    "plt.axis(\"tight\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_knn.best_estimator_, 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), GaussianNB())\n",
    "\n",
    "param_grid = {}\n",
    "grid_bayes = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, scoring= 'f1_macro',  n_jobs=-1)\n",
    "grid_bayes.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_bayes.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_bayes.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_bayes.best_estimator_, 'Bayes Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Decision Tree CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "criterion = 'gini'\n",
    "\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), DecisionTreeClassifier(criterion = criterion, random_state = 2))\n",
    "\n",
    "param_grid = {'decisiontreeclassifier__max_depth': range(1,30,5), 'decisiontreeclassifier__min_samples_leaf': range(1,30,5)}\n",
    "grid_cart = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, scoring= 'f1_macro',  n_jobs=-1)\n",
    "grid_cart.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_cart.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_cart.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame.from_dict(grid_cart.cv_results_, orient='columns')\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=result_df,\n",
    "    kind='line',\n",
    "    x='param_decisiontreeclassifier__max_depth',\n",
    "    y='mean_test_score',\n",
    "#    hue='param_scaler',\n",
    "    col='param_decisiontreeclassifier__min_samples_leaf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_cart.best_estimator_, 'Decision Tree CART')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Decision tree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(grid_cart.best_estimator_[2], out_file=None, \n",
    "            filled=True, rounded=True, feature_names=X_train.columns, class_names=['0','1'])\n",
    "graph = graphviz.Source(dot_data)   \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Decision Tree C5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "criterion = 'entropy'\n",
    "\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), DecisionTreeClassifier(criterion = criterion, random_state = 2))\n",
    "\n",
    "param_grid = {'decisiontreeclassifier__max_depth': range(1,30), 'decisiontreeclassifier__min_samples_leaf': range(1,30)}\n",
    "grid_c50 = GridSearchCV(pipe, param_grid, return_train_score=True, cv=3, scoring= 'f1_macro',  n_jobs=-1)\n",
    "grid_c50.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_c50.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_c50.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Confusion matrix & ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_c50.best_estimator_, 'Decision Tree C5.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Decision tree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(grid_c50.best_estimator_[2], out_file=None, \n",
    "            filled=True, rounded=True, feature_names=X_train.columns, class_names=['0','1'])\n",
    "graph = graphviz.Source(dot_data)   \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create pipe\n",
    "pipe = make_imb_pipeline(RandomOverSampler(sampling_strategy='not majority', random_state=2), Normalizer(), GradientBoostingClassifier(warm_start=True, random_state=2))\n",
    "\n",
    "# cross validations\n",
    "cv = 3\n",
    "\n",
    "\n",
    "param_grid = {\"gradientboostingclassifier__n_estimators\": [50,60,70,80]\n",
    "            ,'gradientboostingclassifier__max_depth' : [6,7,8,9]\n",
    "            ,'gradientboostingclassifier__learning_rate' : [0.1]\n",
    "            \n",
    "             }\n",
    "\n",
    "grid_gb = GridSearchCV(pipe, param_grid, return_train_score=True, cv=cv\n",
    "                       , scoring= 'f1_macro'\n",
    "                       ,n_jobs=-1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid_gb.best_score_))\n",
    "print(\"best parameters: {}\".format(grid_gb.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_gb.best_estimator_, 'Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_estimator = grid_gb.best_estimator_\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 20]\n",
    "\n",
    "#best_model_log.steps[3]\n",
    "feat_importances = best_estimator.named_steps['gradientboostingclassifier'].feature_importances_\n",
    "\n",
    "feat_importances = pd.Series(feat_importances, index=X_train.columns)\n",
    "\n",
    "feat_importances.nlargest(55).plot(kind='barh',title = 'Feature Importance')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "\n",
    "feat_importances_gb = feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#pd.set_option('precision', 2)\n",
    "pd.options.display.float_format = \"{:,.3f}\".format\n",
    "# merge results\n",
    "\n",
    "#y_pred.shape\n",
    "overview = X_test.copy(deep=True)\n",
    "\n",
    "overview['pred_attrition'] = y_pred.tolist()\n",
    "\n",
    "overview = overview.groupby(['pred_attrition']).mean().T\n",
    "\n",
    "overview['feat_importance'] = feat_importances.tolist()\n",
    "overview.nlargest(55, columns = 'feat_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Lift Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_lift_curve(y_val, y_pred, step=0.01):\n",
    "    \n",
    "    #Define an auxiliar dataframe to plot the curve\n",
    "    aux_lift = pd.DataFrame()\n",
    "    #Create a real and predicted column for our new DataFrame and assign values\n",
    "    aux_lift['real'] = y_val\n",
    "    aux_lift['predicted'] = y_pred\n",
    "    #Order the values for the predicted probability column:\n",
    "    aux_lift.sort_values('predicted',ascending=False,inplace=True)\n",
    "    \n",
    "    #Create the values that will go into the X axis of our plot\n",
    "    x_val = np.arange(step,1+step,step)\n",
    "    #Calculate the ratio of ones in our data\n",
    "    ratio_ones = aux_lift['real'].sum() / len(aux_lift)\n",
    "    #Create an empty vector with the values that will go on the Y axis our our plot\n",
    "    y_v = []\n",
    "    \n",
    "    #Calculate for each x value its correspondent y value\n",
    "    for x in x_val:\n",
    "        num_data = int(np.ceil(x*len(aux_lift))) #The ceil function returns the closest integer bigger than our number \n",
    "        data_here = aux_lift.iloc[:num_data,:]   # ie. np.ceil(1.4) = 2\n",
    "        ratio_ones_here = data_here['real'].sum()/len(data_here)\n",
    "        y_v.append(ratio_ones_here / ratio_ones)\n",
    "           \n",
    "   #Plot the figure\n",
    "    fig, axis = plt.subplots()\n",
    "    fig.figsize = (60,60)\n",
    "    axis.plot(x_val, y_v, 'g-', linewidth = 3, markersize = 5)\n",
    "    axis.plot(x_val, np.ones(len(x_val)), 'k-')\n",
    "    axis.set_xlabel('Proportion of sample')\n",
    "    axis.set_ylabel('Lift')\n",
    "    plt.title('Lift Curve')\n",
    "    plt.show()\n",
    "    plt.rcParams['figure.figsize'] = [6, 4]\n",
    "    \n",
    "    return y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_lift_curve(y_test, y_pred, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Work with data imbalance and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='not majority', random_state=2)\n",
    "# fit and apply the transform\n",
    "X_trainD, y_trainD = oversample.fit_resample(X_trainD, y_trainD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaler = Normalizer()\n",
    "X_trainD_norm = scaler.fit_transform(X_trainD)\n",
    "X_valid_norm = scaler.transform(X_valid)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_trainD_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ANN find best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[53]): \n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "            model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "            options = {} \n",
    "    model.add(keras.layers.Dense(1, **options)) \n",
    "    #optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    optimizer='adam'\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    model.compile(loss=loss, optimizer=optimizer,metrics=['accuracy'])\n",
    "    #model.compile(loss=\"mse\", optimizer=optimizer) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "      #  \"n_hidden\": range(1,10,2),\n",
    "      #  \"n_neurons\": np.arange(1, 40),\n",
    "        \"n_hidden\": [9],\n",
    "        \"n_neurons\": [39],\n",
    "        \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_trainD_norm, y_trainD, epochs=100,\n",
    "                  validation_data=(X_valid_norm, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_ann = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_proba = model_ann.predict(X_test_norm)\n",
    "y_score = np.array(y_proba)#[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='ANN')\n",
    "display.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = model_ann.predict(X_test_norm)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "y_pred_binary = (model_ann.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "print('AUC:',auc)\n",
    "print('Accuracy:',accuracy_score(y_test, y_pred_binary))\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "#explainer = shap.DeepExplainer(model_ann,X_trainD_norm)\n",
    "#explainer = shap.PermutationExplainer(model_ann,X_trainD_norm[:50,:])\n",
    "explainer = shap.KernelExplainer(model_ann,X_trainD_norm[:50,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_trainD_norm[50:500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_trainD_norm[50:70,:])\n",
    "#shap_values = explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0], X_trainD_norm[50:70,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Summary Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "\n",
    "\n",
    "estimators = {'Decision tree C5.0' : grid_c50.best_estimator_,\n",
    "             'Decision Tree CART' : grid_cart.best_estimator_,\n",
    "              'Bayes Classification' : grid_bayes.best_estimator_,\n",
    "              'KNN' : grid_knn.best_estimator_,\n",
    "              'Linear SVC' : grid_svc.best_estimator_,\n",
    "              'Logistic Regression' : grid_log.best_estimator_,\n",
    "              'Random Forest' : grid_rf.best_estimator_,\n",
    "              'ANN' : model_ann,\n",
    "              'Gradient Boost' : grid_gb.best_estimator_,\n",
    "             }\n",
    "\n",
    "for key in estimators:\n",
    "\n",
    "    best_estimator = estimators[key]\n",
    "    \n",
    "    if key in ['Linear SVC']:\n",
    "        y_pred = best_estimator.decision_function(X_test)\n",
    "    elif key in ['ANN']:\n",
    "        y_pred = best_estimator.predict(X_test_norm)\n",
    "    else:\n",
    "        y_pred = best_estimator.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "    plt.plot(fpr,tpr,label=key+', AUC='+str(auc))\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Overview of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models_overview = pd.DataFrame(columns=['Accuracy score train','Accuracy score test','F1 score train','F1 score test','AuC_train','AuC_test'])\n",
    "\n",
    "estimators = {'Decision tree C5.0' : grid_c50.best_estimator_,\n",
    "             'Decision Tree CART' : grid_cart.best_estimator_,\n",
    "              'Bayes Classification' : grid_bayes.best_estimator_,\n",
    "              'KNN' : grid_knn.best_estimator_,\n",
    "              'Linear SVC' : grid_svc.best_estimator_,\n",
    "              'Logistic Regression' : grid_log.best_estimator_,\n",
    "              'Random Forest' : grid_rf.best_estimator_,\n",
    "              'ANN' : model_ann,\n",
    "              'Gradient Boost' : grid_gb.best_estimator_,\n",
    "             }\n",
    "\n",
    "# AuC test set\n",
    "for key in estimators:\n",
    "\n",
    "    best_estimator = estimators[key]\n",
    "    \n",
    "    if key in ['Linear SVC']:\n",
    "        y_pred = best_estimator.decision_function(X_test)\n",
    "    elif key in ['ANN']:\n",
    "        y_pred = best_estimator.predict(X_test_norm)\n",
    "    else:\n",
    "        y_pred = best_estimator.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "    #f1score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    #models_overview.loc[key] = pd.Series({'AuC_test':auc})\n",
    "    models_overview.loc[key,['AuC_test']] = auc\n",
    "    #models_overview.loc[key,['F1 score test']] = f1score\n",
    "\n",
    "    # AuC train set\n",
    "for key in estimators:\n",
    "\n",
    "    best_estimator = estimators[key]\n",
    "    \n",
    "    if key in ['Linear SVC']:\n",
    "        y_pred = best_estimator.decision_function(X_train)\n",
    "    elif key in ['ANN']:\n",
    "        y_pred = best_estimator.predict(X_trainD_norm)\n",
    "    else:\n",
    "        y_pred = best_estimator.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    if key in ['ANN']:\n",
    "        auc = round(metrics.roc_auc_score(y_trainD, y_pred), 4)\n",
    "        #f1score = f1_score(y_trainD, y_pred)\n",
    "    else:\n",
    "        auc = round(metrics.roc_auc_score(y_train, y_pred), 4)\n",
    "        #f1score = f1_score(y_train, y_pred)\n",
    "    \n",
    "    models_overview.loc[key,['AuC_train']] = auc\n",
    "    #models_overview.loc[key,['F1 score train']] = f1score\n",
    "    \n",
    "# F1 score \n",
    "for key in estimators:\n",
    "\n",
    "    # test data f1\n",
    "    best_estimator = estimators[key]\n",
    "    if key in ['ANN']:\n",
    "        y_pred = (best_estimator.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    models_overview.loc[key,['F1 score test']] = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # train data f1\n",
    "    best_estimator = estimators[key]\n",
    "    if key in ['ANN']:\n",
    "        y_pred = (best_estimator.predict(X_trainD_norm) > 0.5).astype(\"int32\")\n",
    "        models_overview.loc[key,['F1 score train']] = f1_score(y_trainD, y_pred)\n",
    "\n",
    "    else:\n",
    "        y_pred = best_estimator.predict(X_train)\n",
    "        models_overview.loc[key,['F1 score train']] = f1_score(y_train, y_pred)    \n",
    "    \n",
    "# Accuracy score \n",
    "for key in estimators:\n",
    "\n",
    "    # test data f1\n",
    "    best_estimator = estimators[key]\n",
    "    if key in ['ANN']:\n",
    "        y_pred = (best_estimator.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "\n",
    "    models_overview.loc[key,['Accuracy score test']] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # train data f1\n",
    "    best_estimator = estimators[key]\n",
    "    if key in ['ANN']:\n",
    "        y_pred = (best_estimator.predict(X_trainD_norm) > 0.5).astype(\"int32\")\n",
    "        models_overview.loc[key,['Accuracy score train']] = accuracy_score(y_trainD, y_pred)\n",
    "\n",
    "    else:\n",
    "        y_pred = best_estimator.predict(X_train)\n",
    "        models_overview.loc[key,['Accuracy score train']] = accuracy_score(y_train, y_pred)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#models_overview.index.name = 'Model'\n",
    "models_overview[['Accuracy score test','F1 score test','AuC_test']].sort_values(by='AuC_test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## prediction distribution for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = grid_gb.best_estimator_.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "y_pred_df.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [6,6]\n",
    "plt.xlim(0, 1)\n",
    "sns.set_style('white')\n",
    "sns.distplot(y_pred_df, kde=False, color=\"b\", bins = 15).set(title='Probability Distribution of Attrition Risk')\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances_gb\n",
    "feat_importances_svc\n",
    "feat_importances_rf\n",
    "feat_importances_logr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat([feat_importances_gb,feat_importances_rf,feat_importances_svc,feat_importances_logr], axis=1)\n",
    "plot_data = plot_data.sort_values(plot_data.columns[0], ascending = False).head(10)\n",
    "plot_data = plot_data.set_axis(['Gradient Boost', 'Random Forest', 'Linear SVC', 'Logistic Regression'], axis=1, inplace=False)\n",
    "plot_data_rf = plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = plot_data.set_axis(['Gradient Boost', 'Random Forest', 'Linear SVC', 'Logistic Regression'], axis=1, inplace=False)\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4)\n",
    "sns.barplot(x=plot_data.columns[0], y=plot_data.index, data=plot_data, ax = ax1,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data.columns[1], y=plot_data.index, data=plot_data, ax = ax2,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data.columns[2], y=plot_data.index, data=plot_data, ax = ax3,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data.columns[3], y=plot_data.index, data=plot_data, ax = ax4,\n",
    "            label=\"Total\", color=\"b\")\n",
    "\n",
    "ax2.set(yticklabels=[])\n",
    "ax3.set(yticklabels=[])\n",
    "ax4.set(yticklabels=[])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat([feat_importances_gb,feat_importances_rf,feat_importances_svc,feat_importances_logr], axis=1)\n",
    "plot_data = plot_data.sort_values(plot_data.columns[2], ascending = False).head(10)\n",
    "plot_data = plot_data.set_axis(['Gradient Boost', 'Random Forest', 'Linear SVC', 'Logistic Regression'], axis=1, inplace=False)\n",
    "plot_data_svc_pos = plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "f, (ax3, ax4) = plt.subplots(1,2)\n",
    "sns.barplot(x=plot_data.columns[2], y=plot_data.index, data=plot_data, ax = ax3,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data.columns[3], y=plot_data.index, data=plot_data, ax = ax4,\n",
    "            label=\"Total\", color=\"b\")\n",
    "\n",
    "\n",
    "ax4.set(yticklabels=[])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat([feat_importances_gb,feat_importances_rf,feat_importances_svc,feat_importances_logr], axis=1)\n",
    "plot_data = plot_data.sort_values(plot_data.columns[2], ascending = True).head(10)\n",
    "plot_data = plot_data.set_axis(['Gradient Boost', 'Random Forest', 'Linear SVC', 'Logistic Regression'], axis=1, inplace=False)\n",
    "plot_data_svc_neg = plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "\n",
    "f, (ax3, ax4) = plt.subplots(1,2)\n",
    "sns.barplot(x=plot_data.columns[2], y=plot_data.index, data=plot_data, ax = ax3,\n",
    "            label=\"Total\", color=\"r\")\n",
    "sns.barplot(x=plot_data.columns[3], y=plot_data.index, data=plot_data, ax = ax4,\n",
    "            label=\"Total\", color=\"r\")\n",
    "\n",
    "\n",
    "ax4.set(yticklabels=[])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.concat([feat_importances_gb,feat_importances_rf,feat_importances_svc,feat_importances_logr], axis=1)\n",
    "plot_data = plot_data.sort_values(plot_data.columns[1], ascending = False).head(20)\n",
    "plot_data = plot_data.set_axis(['Gradient Boost', 'Random Forest', 'Linear SVC', 'Logistic Regression'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "sns.barplot(x=plot_data.columns[1], y=plot_data.index, data=plot_data, ax = ax1,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data.columns[0], y=plot_data.index, data=plot_data, ax = ax2,\n",
    "            label=\"Total\", color=\"b\")\n",
    "\n",
    "\n",
    "ax2.set(yticklabels=[])\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [13, 10]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3,2)\n",
    "sns.barplot(x=plot_data.columns[0], y=plot_data.index, data=plot_data, ax = ax1,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data.columns[1], y=plot_data.index, data=plot_data, ax = ax2,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data_svc_pos.columns[2], y=plot_data_svc_pos.index, data=plot_data_svc_pos, ax = ax3,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data_svc_pos.columns[3], y=plot_data_svc_pos.index, data=plot_data_svc_pos, ax = ax4,\n",
    "            label=\"Total\", color=\"b\")\n",
    "sns.barplot(x=plot_data_svc_neg.columns[2], y=plot_data_svc_neg.index, data=plot_data_svc_neg, ax = ax5,\n",
    "            label=\"Total\", color=\"r\")\n",
    "sns.barplot(x=plot_data_svc_neg.columns[3], y=plot_data_svc_neg.index, data=plot_data_svc_neg, ax = ax6,\n",
    "            label=\"Total\", color=\"r\")\n",
    "\n",
    "ax2.set(yticklabels=[])\n",
    "#ax3.set(yticklabels=[])\n",
    "ax4.set(yticklabels=[])\n",
    "ax6.set(yticklabels=[])\n",
    "\n",
    "ax3.set_xlim(0,60)\n",
    "ax5.set_xlim(-60,0)\n",
    "ax4.set_xlim(0,360)\n",
    "ax6.set_xlim(-360,0)\n",
    "\n",
    "ax1.set(xlabel='(a)', title='Gradient Boost')\n",
    "ax2.set(xlabel='(b)', title='Random Forest')\n",
    "ax3.set(xlabel='(c)', title='Linear SVC')\n",
    "ax4.set(xlabel='(d)', title='Logistic Regression')\n",
    "ax5.set(xlabel='(e)', title='Linear SVC')\n",
    "ax6.set(xlabel='(f)', title='Logistic Regression')\n",
    "\n",
    "plt.tight_layout(pad=1.0)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
